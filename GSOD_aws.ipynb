{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the AWS Global Surface Summary of the Day data notebook!\n",
    "#### **Audience:** Anybody with a computer and access to at least 4GB of memory.\n",
    "#### **Intent:** Build familiarity with GSOD data and understand how it could be used in analysis. \n",
    "#### **Outcome:** Statistics and plots for one selected surface station over its entire data record.          \n",
    "\n",
    "The NOAA Global Surface Summary of the Day (GSOD) dataset contains information from over 9,000 weather stations worldwide. These stations often measure these 18 variables: Mean temperature, Mean dew point, Mean sea level pressure, Mean station pressure, Mean visibility, Mean wind speed, Maximum sustained wind speed, Maximum wind gust, Maximum temperature, Minimum temperature, Precipitation amount, Snow depth, and Indicator for occurrence of: Fog, Rain or Drizzle, Snow or Ice Pellets, Hail, Thunder, Tornado/Funnel Cloud. Each station has a different period of record, though the earliest files contained in GSOD were recorded in 1929, and the most recent files are current and available 1-2 days after the observations were recorded. See documentation here: https://data.noaa.gov/dataset/dataset/global-surface-summary-of-the-day-gsod.\n",
    "\n",
    "This notebook will use GSOD data to perform an analysis of a weather station's complete record, producing a local synopsis of the most relevent weather variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Read and follow these steps below before beginning the notebook.**     \n",
    "1. Open the URL (https://www.ncei.noaa.gov/maps/daily/?layers=0001) to see the global dataset. \n",
    "2. Using the map, pan to your region of interest to see available stations.  \n",
    "3. Select the blue wrench icon to the right of the \"Global Summary of the Day\" layer in the lefthand menu. Use a tool to select your desired station(s) to analyze. \n",
    "4. Click the blue \"Download Station List\" icon to download a csv file labeled \"stations.csv\". \n",
    "5. Look through the .csv file to decide which station(s) you'd like to analyze. Base your decisions off of:\n",
    "    - The station's period of record (how much data is available for this station?)\n",
    "    - The station's location (how close is the station to your area of interest?)\n",
    "    - The station's elevation (is the elevation of the station similar to that of your interest area?)\n",
    "6. Copy the STATION_ID number and replace the number in the station_id variable in the cell below.\n",
    "7. You're ready to begin making interesting plots and observations about your local weather station!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "station_id = \"72315003812\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import s3fs\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the definitions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#getting variables from AWS\n",
    "\n",
    "currentYear = datetime.now().year\n",
    "year_options = list(range(1900, currentYear+1))\n",
    "\n",
    "date_list = []\n",
    "temp_list = []\n",
    "max_list = []\n",
    "min_list = []\n",
    "slp_list = []\n",
    "wdsp_list = []\n",
    "gust_list = []\n",
    "prcp_list = []\n",
    "sndp_list = []\n",
    "\n",
    "for year in year_options:\n",
    "    try:\n",
    "        df = pd.read_csv(f'https://noaa-gsod-pds.s3.amazonaws.com/{year}/{station_id}.csv')\n",
    "\n",
    "        date_list.append(df.DATE)\n",
    "        temp_list.append(df.TEMP)\n",
    "        min_list.append(df.MIN)\n",
    "        max_list.append(df.MAX)\n",
    "        slp_list.append(df.SLP)\n",
    "        wdsp_list.append(df.WDSP)\n",
    "        gust_list.append(df.GUST)\n",
    "        prcp_list.append(df.PRCP)\n",
    "        sndp_list.append(df.SNDP)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "dates = pd.concat(date_list, ignore_index=True)\n",
    "temps = pd.concat(temp_list, ignore_index=True)\n",
    "mins = pd.concat(min_list, ignore_index=True)\n",
    "maxs = pd.concat(max_list, ignore_index=True)\n",
    "slps = pd.concat(slp_list, ignore_index=True)\n",
    "wdsps = pd.concat(wdsp_list, ignore_index=True)\n",
    "gusts = pd.concat(gust_list, ignore_index=True)\n",
    "prcps = pd.concat(prcp_list, ignore_index=True)\n",
    "sndps = pd.concat(sndp_list, ignore_index=True)\n",
    "\n",
    "# Put lists together\n",
    "df_concat = pd.concat([dates, temps, mins, maxs, slps, wdsps, gusts, prcps, sndps], axis=1)\n",
    "\n",
    "# Change datetime formats\n",
    "df_concat.DATE = pd.to_datetime(df_concat.DATE, format='%Y-%m-%d') \n",
    "df_concat[\"day\"] = df_concat.DATE.dt.strftime('%b %d')\n",
    "df_concat[\"year\"] = df_concat.DATE.dt.strftime('%Y')\n",
    "df_concat[\"month\"] = df_concat.DATE.dt.strftime('%m')\n",
    "df_concat = df_concat[df_concat.day != \"Feb 29\"]\n",
    "\n",
    "# QC\n",
    "df_concat = df_concat.replace(9999.9, np.nan)\n",
    "df_concat = df_concat.replace(999.9, np.nan)\n",
    "df_concat = df_concat.replace(99.99, np.nan)\n",
    "\n",
    "# Average variables\n",
    "df_averaged = df_concat.groupby(df_concat.day).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# High temperature\n",
    "def high_temps():\n",
    "    fig, ax = plt.subplots(figsize=(10, 2), dpi=300)\n",
    "    plt.scatter(df_concat[\"day\"], df_concat[\"year\"], cmap = \"turbo\", s=2,c= df_concat[\"MAX\"], marker=\"s\")\n",
    "\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(13))\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(10))\n",
    "    plt.gca().invert_yaxis()\n",
    "    ax.margins(x=0, y=0.03)\n",
    "\n",
    "    plt.colorbar(label = \"Temperature (\\u00b0F)\")\n",
    "    plt.title(\"Daily High Temperatures\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    # Fun stats\n",
    "    hot_day = (df_concat.loc[df_concat['MAX'] == max(df_concat.MAX)]).day.values[0]\n",
    "    hot_year = (df_concat.loc[df_concat['MAX'] == max(df_concat.MAX)]).year.values[0]\n",
    "    print(f\"The hottest temperature ever recorded for your location was {max(df_concat.MAX)}\\u00b0F on {hot_day}, {hot_year}.\")\n",
    "    \n",
    "    exceed_100 = df_concat[df_concat.MAX >= 100]\n",
    "    count_100 = exceed_100.groupby('year').count()       \n",
    "    print(f\"On average, your location meets or exceeds 100\\u00b0F {count_100.MAX.sum()/len(pd.unique(df_concat['year']))} times per year.\")\n",
    "    \n",
    "    print(f\"The hottest 'high temperature' typically occurs on {df_averaged['MAX'].idxmax()} and averages {round(max(df_averaged.MAX), 1)}\\u00b0F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Low temperature\n",
    "def low_temps():\n",
    "    df_concat.MIN[df_concat.MIN > 32] = np.nan\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 2), dpi=300)\n",
    "\n",
    "    plt.scatter(df_concat[\"day\"], df_concat[\"year\"], cmap = \"gist_rainbow\",s=2,c= df_concat[\"MIN\"], marker=\"s\")\n",
    "\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(13))\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(10))\n",
    "    plt.gca().invert_yaxis()\n",
    "    ax.margins(x=0, y=0.03)\n",
    "\n",
    "    plt.colorbar(label = \"Temperature (\\u00b0F)\")\n",
    "    plt.title(\"Freezing Temperatures (Below 32\\u00b0F)\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    # Cold stats\n",
    "    cold_day = (df_concat.loc[df_concat['MIN'] == np.nanmin(df_concat.MIN)]).day.values[0]\n",
    "    cold_year = (df_concat.loc[df_concat['MIN'] == np.nanmin(df_concat.MIN)]).year.values[0]\n",
    "    print(f\"The coldest temperature ever recorded for your location is {np.nanmin(df_concat.MIN)}\\u00b0F on {cold_day}, {cold_year}.\")\n",
    "\n",
    "    freezing = df_concat[df_concat.MIN <= 32]\n",
    "    freezing[\"month\"] = freezing[\"month\"].astype(int)\n",
    "    \n",
    "    try:\n",
    "        late_freeze = freezing.loc[(freezing.month > 4) & (freezing.month < 8)]\n",
    "        freeze_year = (late_freeze.loc[late_freeze['day'] == max(late_freeze.day)].year.values[0])\n",
    "        print(f\"There have been {len(pd.unique(late_freeze['year']))} years in the weather record where a freeze occurred on or after May 1st, where the latest ever freeze occurred on {max(late_freeze.day)}, {freeze_year}.\")\n",
    "\n",
    "    except:\n",
    "        print(\"There are no instances of late freezes occurring on or after May 1st.\")\n",
    "\n",
    "    try:\n",
    "        early_freeze = freezing.loc[(freezing.month > 6) & (freezing.month < 10)]\n",
    "        early_freeze_year = (early_freeze.loc[early_freeze['day'] == min(early_freeze.day)].year.values[0])\n",
    "        print(f\"There have been {len(pd.unique(early_freeze['year']))} years in the weather record where a freeze occurred before October 1st, where the earliest ever freeze occurred on {min(early_freeze.day)}, {early_freeze_year}.\")\n",
    "    except:\n",
    "        print(\"There are no instances of early freezes occurring before October 1st.\")\n",
    "        \n",
    "    print(f\"The coldest 'low temperature' typically occurs on {df_averaged['MIN'].idxmin()} and averages {round(min(df_averaged.MIN), 1)}\\u00b0F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Precip amounts\n",
    "def precip_amount():\n",
    "    df_concat[\"PRCP\"] = df_concat[\"PRCP\"].replace(0, np.nan)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 2), dpi=300)\n",
    "\n",
    "    plt.scatter(df_concat[\"day\"], df_concat[\"year\"], cmap = 'jet', vmin = 0, vmax = 2, s=2,c= df_concat[\"PRCP\"], marker=\"s\")\n",
    "\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(13))\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(10))\n",
    "    plt.gca().invert_yaxis()\n",
    "    ax.margins(x=0, y=0.03)\n",
    "\n",
    "    plt.colorbar(label = \"Precipitation (in)\")\n",
    "    plt.title(\"Precipitation\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    # Rain facts\n",
    "\n",
    "    rain_day = (df_concat.loc[df_concat['PRCP'] == np.nanmax(df_concat.PRCP)]).day.values[0]\n",
    "    rain_year = (df_concat.loc[df_concat['PRCP'] == np.nanmax(df_concat.PRCP)]).year.values[0]\n",
    "\n",
    "    print(f\"The most rain ever recorded for your location is {np.nanmax(df_concat.PRCP)} inches on {rain_day}, {rain_year}.\")\n",
    "    \n",
    "    cumulative_year = df_concat.groupby('year').PRCP.sum()\n",
    "    cumulative_year = cumulative_year[1:-1]\n",
    "    print(f\"The rainiest year on record was {cumulative_year.idxmax()}, with {max(cumulative_year)} inches of rain.\")\n",
    "    print(f\"The driest year on record was {cumulative_year.idxmin()}, with {min(cumulative_year)} inches of rain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Snow depths\n",
    "def snow_depth():\n",
    "    df_concat[\"SNDP\"] = df_concat[\"SNDP\"].replace(999.9, np.nan)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 2), dpi=300)\n",
    "\n",
    "    plt.scatter(df_concat[\"day\"], df_concat[\"year\"], s=2,c= df_concat[\"SNDP\"], marker=\"s\")\n",
    "\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(13))\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(10))\n",
    "    plt.gca().invert_yaxis()\n",
    "    ax.margins(x=0, y=0.03)\n",
    "\n",
    "    plt.colorbar(label = \"Snow depth (in)\")\n",
    "    plt.title(\"Snow Depth\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    # Snow facts\n",
    "\n",
    "    snow_day = (df_concat.loc[df_concat['SNDP'] == np.nanmax(df_concat.SNDP)]).day.values[0]\n",
    "    snow_year = (df_concat.loc[df_concat['SNDP'] == np.nanmax(df_concat.SNDP)]).year.values[0]\n",
    "    \n",
    "    years_with_snow = df_concat.loc[(df_concat.SNDP > 0)]\n",
    "\n",
    "    print(f\"The most snow ever recorded at your location is {np.nanmax(df_concat.SNDP)} inches on {snow_day}, {snow_year}.\")\n",
    "    print(f\"{len(pd.unique(years_with_snow['year']))} out of {len(pd.unique(df_concat['year']))} years in this station's record have had measureable snowfall.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sea level pressure\n",
    "def sea_level_pressure():\n",
    "    fig, ax = plt.subplots(figsize=(10, 2), dpi=300)\n",
    "    plt.scatter(df_concat[\"day\"], df_concat[\"year\"], s=2, c= df_concat[\"SLP\"], marker=\"s\")\n",
    "\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(13))\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(10))\n",
    "    plt.gca().invert_yaxis()\n",
    "    ax.margins(x=0, y=0.03)\n",
    "\n",
    "    plt.colorbar(label = \"Sea level pressure (hPa)\")\n",
    "    plt.title(\"Sea level pressure\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wind speeds\n",
    "def wind_speeds():\n",
    "    fig, ax = plt.subplots(figsize=(10, 2), dpi=300)\n",
    "\n",
    "    plt.scatter(df_concat[\"day\"], df_concat[\"year\"], s=2,c= df_concat[\"WDSP\"], marker=\"s\")\n",
    "\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(13))\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(10))\n",
    "    plt.gca().invert_yaxis()\n",
    "    ax.margins(x=0, y=0.03)\n",
    "\n",
    "    plt.colorbar(label = \"Wind speed (knots)\")\n",
    "    plt.title(\"Mean Wind Speed\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wind gusts\n",
    "def wind_gust():\n",
    "    fig, ax = plt.subplots(figsize=(10, 2), dpi=300)\n",
    "\n",
    "    plt.scatter(df_concat[\"day\"], df_concat[\"year\"], s=2,c= df_concat[\"GUST\"], marker=\"s\")\n",
    "\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(13))\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(10))\n",
    "    plt.gca().invert_yaxis()\n",
    "    ax.margins(x=0, y=0.03)\n",
    "\n",
    "    plt.colorbar(label = \"Wind Gust (knots)\")\n",
    "    plt.title(\"Maximum Daily Wind Gust\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "    gust_day = (df_concat.loc[df_concat['GUST'] == np.nanmax(df_concat.GUST)]).day.values[0]\n",
    "    gust_year = (df_concat.loc[df_concat['GUST'] == np.nanmax(df_concat.GUST)]).year.values[0]\n",
    "    print(f\"The strongest wind gust ever recorded for your location is {np.nanmax(df_concat.GUST)} knots on {gust_day}, {gust_year}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Find the information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Temperatures! \n",
    "\n",
    "high_temps()\n",
    "low_temps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Precipitation\n",
    "\n",
    "precip_amount()\n",
    "snow_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Surface variables\n",
    "\n",
    "sea_level_pressure()\n",
    "wind_speeds()\n",
    "wind_gust()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GSOD Product Documentation:**\n",
    "- https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.ncdc:C00516 (NCEI dataset landing page)\n",
    "- https://www.ncei.noaa.gov/data/global-summary-of-the-day/doc/readme.txt (Overview of the dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CSP Access:**\n",
    "- AWS: https://registry.opendata.aws/noaa-gsod/\n",
    "- Google: https://console.cloud.google.com/marketplace/details/noaa-public/gsod?filter=solution-type:dataset&q=NOAA&id=c6c1b652-3958-4a47-9e58-552a546df47f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The unique component of this Jupyter notebook is that you are not requried to download any datasets -- all data will be pulled directly from the cloud. You can learn more about NOAA's efforts to move more data to the cloud at this site: https://www.noaa.gov/nodd/datasets. As we continute to make more data widely accessible on the cloud, we'll also create more Jupyter notebooks like this one, so anyone can visualize weather and climate data without any cost or restriction. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
